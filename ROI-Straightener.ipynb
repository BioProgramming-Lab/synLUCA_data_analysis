{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - ROI-Straightener\n",
    "\n",
    "## Overview\n",
    "This script processes microscopy images with associated ROI annotations (LabelMe JSON format) and optional mapping images.  \n",
    "It performs **ROI skeleton extraction**, determines the **longest path** with a controlled start orientation, and straightens the curved ROI region so that the start point is consistently placed on the **left side** of the output.  \n",
    "The same transformation is applied to all mapping images, ensuring spatial correspondence across channels or datasets.  \n",
    "\n",
    "The workflow includes:\n",
    "1. **Validation** of target and mapping datasets.\n",
    "2. **Skeletonization** and **longest path detection** within annotated ROI.\n",
    "3. **Geometric straightening** of target and mapping images.\n",
    "4. **Interactive navigation** to inspect results.\n",
    "5. **Export** as either:\n",
    "   - Individual straightened TIFF images, or\n",
    "   - Multi-frame TIFF stacks.\n",
    "\n",
    "---\n",
    "\n",
    "## Input Requirements\n",
    "- **Target folder** containing pairs of:\n",
    "  - Microscopy image files (`.tif`, `.png`, `.jpg`, etc.)\n",
    "  - Corresponding ROI annotation files in **LabelMe JSON format**.\n",
    "- **Mapping folder(s)** (optional):\n",
    "  - Each mapping folder must contain the same number of images as the target folder.\n",
    "  - Images must have identical dimensions to the corresponding target images.\n",
    "- **Directory structure example**:\n",
    "  ```\n",
    "  TARGET_DIR/\n",
    "      sample1.tif\n",
    "      sample1.json\n",
    "      sample2.tif\n",
    "      sample2.json\n",
    "  MAPPING_DIRS/\n",
    "      Mapping1/\n",
    "          sample1.tif\n",
    "          sample2.tif\n",
    "      Mapping2/\n",
    "          sample1.tif\n",
    "          sample2.tif\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "## Outputs\n",
    "- **Straightened target and mapping images** with consistent start orientation.\n",
    "- **Individual TIFF files** for each processed image:\n",
    "  ```\n",
    "  sample1_target_straight.tif\n",
    "  sample1_map_Mapping1_straight.tif\n",
    "  ...\n",
    "  ```\n",
    "- **Multi-frame TIFF stacks**:\n",
    "  ```\n",
    "  Target_Stack.tif\n",
    "  Mapping1_Stack.tif\n",
    "  Mapping2_Stack.tif\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "## How to Run\n",
    "1. **Set directory paths**:\n",
    "   - Edit `TARGET_DIR`, `MAPPING_DIRS`, and `OUTPUT_DIR` in the configuration cell.\n",
    "2. **Run validation**:\n",
    "   - Executes `validate_and_load_files()` to ensure file count and dimensions match.\n",
    "3. **Process images**:\n",
    "   - Calls `process_single_image_set()` for each image pair.\n",
    "4. **Inspect results interactively**:\n",
    "   - Use the navigation widget to browse straightened results.\n",
    "5. **Save outputs**:\n",
    "   - Use the save buttons to export either individual files or TIFF stacks.\n",
    "\n",
    "**Example run sequence** (inside Jupyter Notebook):\n",
    "```python\n",
    "# Step 1: Validate\n",
    "validation_result = validate_and_load_files(TARGET_DIR, MAPPING_DIRS)\n",
    "\n",
    "# Step 2: Process all images\n",
    "all_results = [process_single_image_set(f) for f in file_list_map]\n",
    "\n",
    "# Step 3: Inspect interactively\n",
    "create_navigation_controls()\n",
    "\n",
    "# Step 4: Save\n",
    "create_save_controls()\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from skimage.morphology import skeletonize as skel_func\n",
    "from skan import Skeleton as SkanSkeleton\n",
    "from scipy.sparse.csgraph import dijkstra\n",
    "import math\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set matplotlib to display images inline with high quality\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['image.interpolation'] = 'bilinear'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set your input and output directories and skeleton orientation preferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target directory: /Users/jyzerresico/chenlab/Synthetic Division/Fig4d/ACA-5/c1\n",
      "Mapping directories: ['/Users/jyzerresico/chenlab/Synthetic Division/Fig4d/ACA-5/c2']\n",
      "Output directory: /Users/jyzerresico/chenlab/Synthetic Division/Fig4d/ACA-5/Straightener\n",
      "Save as stack: False\n",
      "Pad to canvas: False\n",
      "Skeleton start preference: top -> START will be on LEFT side of output\n",
      "Upscale factor for display: 2x\n"
     ]
    }
   ],
   "source": [
    "# Configuration - Update these paths according to your data\n",
    "TARGET_DIR = \"/Users/jyzerresico/chenlab/Synthetic Division/Fig4d/ACA-5/c1\"  # Folder containing images and JSON files\n",
    "\n",
    "MAPPING_DIRS = [\n",
    "    \"/Users/jyzerresico/chenlab/Synthetic Division/Fig4d/ACA-5/c2\"  # Add more mapping folders as needed\n",
    "]\n",
    "OUTPUT_DIR = \"/Users/jyzerresico/chenlab/Synthetic Division/Fig4d/ACA-5/Straightener\"  # Where to save results\n",
    "\n",
    "# Output options\n",
    "SAVE_AS_STACK = False  # True for multi-frame TIFF stacks, False for individual files\n",
    "PAD_TO_CANVAS = False  # True to pad/crop to fixed canvas size\n",
    "OUTPUT_WIDTH = 200     # Canvas width (only used if PAD_TO_CANVAS=True)\n",
    "OUTPUT_HEIGHT = 200    # Canvas height (only used if PAD_TO_CANVAS=True)\n",
    "\n",
    "# Skeleton orientation control\n",
    "# Options: 'top', 'bottom', 'left', 'right'\n",
    "# This determines which end of the skeleton will be the START point\n",
    "# START point will always appear on LEFT side of straightened output\n",
    "SKELETON_START_PREFERENCE = 'top'  # Change this to control skeleton orientation\n",
    "\n",
    "# Visualization options for better display quality\n",
    "CONTOUR_THICKNESS = 1      # Thickness for polygon contours (1 for fine lines)\n",
    "SKELETON_THICKNESS = 1     # Thickness for skeleton lines\n",
    "PATH_THICKNESS = 2         # Thickness for longest path\n",
    "UPSCALE_FACTOR = 2         # Factor to upscale images for better visualization\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Target directory: {TARGET_DIR}\")\n",
    "print(f\"Mapping directories: {MAPPING_DIRS}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Save as stack: {SAVE_AS_STACK}\")\n",
    "print(f\"Pad to canvas: {PAD_TO_CANVAS}\")\n",
    "print(f\"Skeleton start preference: {SKELETON_START_PREFERENCE} -> START will be on LEFT side of output\")\n",
    "print(f\"Upscale factor for display: {UPSCALE_FACTOR}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core processing functions defined successfully!\n",
      "Skeleton orientation control with START point on LEFT side\n"
     ]
    }
   ],
   "source": [
    "def upscale_image_for_display(image, factor=2):\n",
    "    \"\"\"Upscale image for better visualization quality.\"\"\"\n",
    "    if factor <= 1:\n",
    "        return image\n",
    "    height, width = image.shape[:2]\n",
    "    new_height, new_width = height * factor, width * factor\n",
    "    return cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "def draw_polygon_with_fine_lines(image, polygon_points, color=(0, 255, 0), thickness=1, upscale_factor=1):\n",
    "    \"\"\"Draw polygon with fine lines optimized for low resolution images.\"\"\"\n",
    "    img_copy = image.copy()\n",
    "    \n",
    "    if upscale_factor > 1:\n",
    "        img_copy = upscale_image_for_display(img_copy, upscale_factor)\n",
    "        # Scale polygon points accordingly\n",
    "        scaled_points = (polygon_points * upscale_factor).astype(np.int32)\n",
    "    else:\n",
    "        scaled_points = polygon_points.astype(np.int32)\n",
    "    \n",
    "    # Draw with anti-aliasing for smoother lines\n",
    "    cv2.polylines(img_copy, [scaled_points], isClosed=True, color=color, \n",
    "                 thickness=thickness, lineType=cv2.LINE_AA)\n",
    "    \n",
    "    return img_copy\n",
    "\n",
    "\n",
    "def select_skeleton_start_point(endpoint_coordinates, preference='top'):\n",
    "    \"\"\"Select skeleton start point based on spatial preference.\n",
    "    \n",
    "    Args:\n",
    "        endpoint_coordinates: Array of endpoint coordinates in (row, col) format\n",
    "        preference: 'top', 'bottom', 'left', 'right'\n",
    "    \n",
    "    Returns:\n",
    "        Index of the selected start point\n",
    "    \"\"\"\n",
    "    if len(endpoint_coordinates) < 2:\n",
    "        return 0\n",
    "    \n",
    "    if preference == 'top':\n",
    "        # Select point with smallest row (topmost)\n",
    "        return np.argmin(endpoint_coordinates[:, 0])\n",
    "    elif preference == 'bottom':\n",
    "        # Select point with largest row (bottommost)\n",
    "        return np.argmax(endpoint_coordinates[:, 0])\n",
    "    elif preference == 'left':\n",
    "        # Select point with smallest column (leftmost)\n",
    "        return np.argmin(endpoint_coordinates[:, 1])\n",
    "    elif preference == 'right':\n",
    "        # Select point with largest column (rightmost)\n",
    "        return np.argmax(endpoint_coordinates[:, 1])\n",
    "    else:\n",
    "        # Default to first point\n",
    "        return 0\n",
    "\n",
    "\n",
    "def draw_skeleton_with_path_and_start(skeleton_img, longest_path_coords_rc, start_coord_rc, \n",
    "                                     upscale_factor=1, skeleton_thickness=1, path_thickness=2):\n",
    "    \"\"\"Draw skeleton with highlighted longest path and marked start point.\"\"\"\n",
    "    # Convert to color\n",
    "    if len(skeleton_img.shape) == 2:\n",
    "        skeleton_display = cv2.cvtColor(skeleton_img, cv2.COLOR_GRAY2BGR)\n",
    "    else:\n",
    "        skeleton_display = skeleton_img.copy()\n",
    "    \n",
    "    if upscale_factor > 1:\n",
    "        skeleton_display = upscale_image_for_display(skeleton_display, upscale_factor)\n",
    "        # Scale path coordinates\n",
    "        scaled_path = (longest_path_coords_rc * upscale_factor).astype(np.int32)\n",
    "        scaled_start = (start_coord_rc * upscale_factor).astype(np.int32)\n",
    "    else:\n",
    "        scaled_path = longest_path_coords_rc.astype(np.int32)\n",
    "        scaled_start = start_coord_rc.astype(np.int32)\n",
    "    \n",
    "    # Draw the longest path in red with anti-aliasing\n",
    "    path_xy = scaled_path[:, ::-1]  # Convert rc to xy coordinates\n",
    "    cv2.polylines(skeleton_display, [path_xy], isClosed=False, color=(0, 0, 255), \n",
    "                 thickness=path_thickness, lineType=cv2.LINE_AA)\n",
    "    \n",
    "    # Mark the start point with a green circle\n",
    "    start_xy = scaled_start[::-1]  # Convert rc to xy\n",
    "    radius = max(3, path_thickness + 1)\n",
    "    cv2.circle(skeleton_display, tuple(start_xy.astype(int)), radius, (0, 255, 0), -1, cv2.LINE_AA)\n",
    "    \n",
    "    # Add \"START\" text near the start point\n",
    "    text_pos = (int(start_xy[0] + radius + 5), int(start_xy[1] - radius - 5))\n",
    "    cv2.putText(skeleton_display, \"START\", text_pos, \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "    \n",
    "    return skeleton_display\n",
    "\n",
    "\n",
    "def straighten_polygon_region(image, polygon_mask, skeleton_path_rc):\n",
    "    \"\"\"Straighten a polygonal region along a skeleton path.\n",
    "    \n",
    "    Modified to ensure START point appears on LEFT side of output.\n",
    "    The original algorithm flips the result, so we need to account for this.\n",
    "    \"\"\"\n",
    "    skeleton_path_rc = np.array(skeleton_path_rc, dtype=np.float32)\n",
    "    if len(skeleton_path_rc) < 2:\n",
    "        return np.zeros((10, 10, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Calculate path segments and arc lengths\n",
    "    path_segments = np.diff(skeleton_path_rc, axis=0)\n",
    "    segment_lengths = np.linalg.norm(path_segments, axis=1)\n",
    "    arc_lengths = np.concatenate(([0], np.cumsum(segment_lengths)))\n",
    "    total_skeleton_length = arc_lengths[-1]\n",
    "    \n",
    "    if total_skeleton_length < 1e-3:\n",
    "        return np.zeros((10, 10, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Calculate normals along the path\n",
    "    path_normals_rc = np.zeros_like(skeleton_path_rc)\n",
    "    \n",
    "    # First point normal\n",
    "    tangent_first = skeleton_path_rc[1] - skeleton_path_rc[0]\n",
    "    norm_tangent_first = np.linalg.norm(tangent_first)\n",
    "    if norm_tangent_first < 1e-6:\n",
    "        tangent_first = np.array([1.0, 0.0])\n",
    "    else:\n",
    "        tangent_first /= norm_tangent_first\n",
    "    path_normals_rc[0] = [-tangent_first[1], tangent_first[0]]\n",
    "    \n",
    "    # Middle points normals\n",
    "    for i in range(1, len(skeleton_path_rc) - 1):\n",
    "        tangent = skeleton_path_rc[i+1] - skeleton_path_rc[i-1]\n",
    "        norm_tangent = np.linalg.norm(tangent)\n",
    "        if norm_tangent < 1e-6:\n",
    "            path_normals_rc[i] = path_normals_rc[i-1]\n",
    "        else:\n",
    "            tangent /= norm_tangent\n",
    "            path_normals_rc[i] = [-tangent[1], tangent[0]]\n",
    "    \n",
    "    # Last point normal\n",
    "    tangent_last = skeleton_path_rc[-1] - skeleton_path_rc[-2]\n",
    "    norm_tangent_last = np.linalg.norm(tangent_last)\n",
    "    if norm_tangent_last < 1e-6:\n",
    "        tangent_last = np.array([1.0, 0.0])\n",
    "    else:\n",
    "        tangent_last /= norm_tangent_last\n",
    "    path_normals_rc[-1] = [-tangent_last[1], tangent_last[0]]\n",
    "    \n",
    "    # Find all points in the mask and their perpendicular distances\n",
    "    all_mask_points_rc = np.argwhere(polygon_mask > 0).astype(np.float32)\n",
    "    if len(all_mask_points_rc) == 0:\n",
    "        return None\n",
    "    \n",
    "    all_v_coords = []\n",
    "    for p_rc in all_mask_points_rc:\n",
    "        distances_to_skel_pts_sq = np.sum((skeleton_path_rc - p_rc)**2, axis=1)\n",
    "        closest_skel_pt_idx = np.argmin(distances_to_skel_pts_sq)\n",
    "        vec_skel_to_p = p_rc - skeleton_path_rc[closest_skel_pt_idx]\n",
    "        perp_dist = np.dot(vec_skel_to_p, path_normals_rc[closest_skel_pt_idx])\n",
    "        all_v_coords.append(perp_dist)\n",
    "    \n",
    "    if not all_v_coords:\n",
    "        d_min, d_max = -20, 20\n",
    "    else:\n",
    "        d_min, d_max = np.min(all_v_coords), np.max(all_v_coords)\n",
    "    \n",
    "    # Create output dimensions\n",
    "    output_width_px = int(round(total_skeleton_length))\n",
    "    output_height_px = int(round(d_max - d_min))\n",
    "    if output_width_px <= 0:\n",
    "        output_width_px = 1\n",
    "    if output_height_px <= 0:\n",
    "        output_height_px = 1\n",
    "    \n",
    "    v_offset_display = -d_min\n",
    "    \n",
    "    # Create coordinate maps\n",
    "    # MODIFIED: Reverse the u_param mapping to counteract the final flip\n",
    "    # This ensures START point ends up on LEFT side after flip\n",
    "    map_c_coords = np.zeros((output_height_px, output_width_px), dtype=np.float32)\n",
    "    map_r_coords = np.zeros((output_height_px, output_width_px), dtype=np.float32)\n",
    "    \n",
    "    for r_new in range(output_height_px):\n",
    "        for c_new in range(output_width_px):\n",
    "            # MODIFIED: Reverse the u_param so that after flip, START is on LEFT\n",
    "            u_param = total_skeleton_length - float(c_new)\n",
    "            v_param = float(r_new) - v_offset_display\n",
    "            \n",
    "            skel_pt_idx = np.searchsorted(arc_lengths, u_param, side='right') - 1\n",
    "            skel_pt_idx = max(0, min(skel_pt_idx, len(arc_lengths) - 2))\n",
    "            \n",
    "            segment_start_arc_len = arc_lengths[skel_pt_idx]\n",
    "            segment_len = arc_lengths[skel_pt_idx+1] - segment_start_arc_len\n",
    "            \n",
    "            if segment_len < 1e-6:\n",
    "                interp_ratio = 0.0\n",
    "            else:\n",
    "                interp_ratio = np.clip((u_param - segment_start_arc_len) / segment_len, 0.0, 1.0)\n",
    "            \n",
    "            pt_on_skel_rc = (1 - interp_ratio) * skeleton_path_rc[skel_pt_idx] + interp_ratio * skeleton_path_rc[skel_pt_idx+1]\n",
    "            normal_rc_interp = (1 - interp_ratio) * path_normals_rc[skel_pt_idx] + interp_ratio * path_normals_rc[skel_pt_idx+1]\n",
    "            \n",
    "            norm_of_normal = np.linalg.norm(normal_rc_interp)\n",
    "            if norm_of_normal < 1e-6:\n",
    "                normal_rc_interp = path_normals_rc[skel_pt_idx] if np.linalg.norm(path_normals_rc[skel_pt_idx]) > 1e-6 else np.array([0.0, 1.0])\n",
    "            else:\n",
    "                normal_rc_interp /= norm_of_normal\n",
    "            \n",
    "            map_r_coords[r_new, c_new] = pt_on_skel_rc[0] + v_param * normal_rc_interp[0]\n",
    "            map_c_coords[r_new, c_new] = pt_on_skel_rc[1] + v_param * normal_rc_interp[1]\n",
    "    \n",
    "    # Apply the transformation\n",
    "    masked_source_image = cv2.bitwise_and(image, image, mask=polygon_mask)\n",
    "    straightened_img_content = cv2.remap(masked_source_image, map_c_coords, map_r_coords, \n",
    "                                       interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=(0,0,0))\n",
    "    \n",
    "    # Apply mask to straightened image\n",
    "    mask_float = polygon_mask.astype(np.float32) / 255.0\n",
    "    straightened_mask_float = cv2.remap(mask_float, map_c_coords, map_r_coords, \n",
    "                                      interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n",
    "    final_straightened_mask = (straightened_mask_float > 0.5).astype(np.uint8) * 255\n",
    "    final_output = cv2.bitwise_and(straightened_img_content, straightened_img_content, mask=final_straightened_mask)\n",
    "    \n",
    "    # Keep the original flip behavior, but with reversed u_param mapping\n",
    "    # This ensures START point ends up on LEFT side\n",
    "    final_output = cv2.flip(final_output, -1)\n",
    "    return final_output\n",
    "\n",
    "\n",
    "def pad_and_center_image(img_to_pad, out_width, out_height):\n",
    "    \"\"\"Pad and center an image to a specific canvas size.\"\"\"\n",
    "    if img_to_pad is None:\n",
    "        return np.zeros((out_height, out_width, 3), dtype=np.uint8)\n",
    "    \n",
    "    h, w = img_to_pad.shape[:2]\n",
    "    canvas = np.zeros((out_height, out_width, 3), dtype=np.uint8)\n",
    "    \n",
    "    x_offset = (out_width - w) // 2\n",
    "    y_offset = (out_height - h) // 2\n",
    "    \n",
    "    paste_w, paste_h = min(w, out_width), min(h, out_height)\n",
    "    \n",
    "    if x_offset < 0 or y_offset < 0:\n",
    "        # Image is larger than canvas, crop it\n",
    "        crop_x = (w - out_width) // 2 if w > out_width else 0\n",
    "        crop_y = (h - out_height) // 2 if h > out_height else 0\n",
    "        canvas[:, :] = img_to_pad[crop_y:crop_y+paste_h, crop_x:crop_x+paste_w]\n",
    "    else:\n",
    "        # Image is smaller than canvas, center it\n",
    "        canvas[y_offset:y_offset+paste_h, x_offset:x_offset+paste_w] = img_to_pad[:paste_h, :paste_w]\n",
    "    \n",
    "    return canvas\n",
    "\n",
    "\n",
    "def extract_skeleton_and_longest_path(mask, start_preference='top'):\n",
    "    \"\"\"\n",
    "    Extracts the skeleton and uses a \"hybrid\" logic to find the longest path:\n",
    "    1. Uses a two-pass Dijkstra algorithm to find the physical longest path (diameter).\n",
    "    2. Applies spatial preference to the two endpoints of that path to determine the final start point.\n",
    "    \"\"\"\n",
    "    skeleton_rc = skel_func(mask > 0)\n",
    "    skeleton_display_img = (skeleton_rc.astype(np.uint8) * 255)\n",
    "\n",
    "    graph = SkanSkeleton(skeleton_rc)\n",
    "    pixel_graph, coordinates_rc = graph.graph, graph.coordinates\n",
    "\n",
    "    if pixel_graph.shape[0] == 0:\n",
    "        raise ValueError(\"Skeleton graph is empty.\")\n",
    "\n",
    "    n_nodes = pixel_graph.shape[0]\n",
    "    degrees = np.bincount(pixel_graph.indices, minlength=n_nodes)\n",
    "    endpoint_nodes_indices = np.where(degrees == 1)[0]\n",
    "\n",
    "    longest_path_coords_rc = None\n",
    "    start_coord_rc = None\n",
    "\n",
    "    if len(endpoint_nodes_indices) < 2:\n",
    "        # Fallback to the original skan method if there are fewer than 2 endpoints\n",
    "        if graph.n_paths > 0:\n",
    "            longest_path_idx = np.argmax(graph.path_lengths())\n",
    "            longest_path_coords_rc = graph.path_coordinates(longest_path_idx)\n",
    "            if longest_path_coords_rc is None or len(longest_path_coords_rc) < 2:\n",
    "                raise ValueError(\"Fallback skeleton path is invalid.\")\n",
    "            start_coord_rc = longest_path_coords_rc[0] # The first point becomes the start\n",
    "        else:\n",
    "            raise ValueError(\"No paths found and insufficient endpoints.\")\n",
    "    else:\n",
    "        # --- Find the physical longest path (diameter) using the old logic ---\n",
    "        \n",
    "        # From an arbitrary endpoint, find the farthest endpoint A\n",
    "        temp_start_node = endpoint_nodes_indices[0]\n",
    "        \n",
    "        # The function returns only one value, so assign it to one variable.\n",
    "        distances_from_temp = dijkstra(\n",
    "            csgraph=pixel_graph, directed=False, indices=temp_start_node, return_predecessors=False\n",
    "        )\n",
    "        \n",
    "        farthest_node_A_idx = -1\n",
    "        max_dist = -1\n",
    "        for ep_idx in endpoint_nodes_indices:\n",
    "            if distances_from_temp[ep_idx] > max_dist and np.isfinite(distances_from_temp[ep_idx]):\n",
    "                max_dist = distances_from_temp[ep_idx]\n",
    "                farthest_node_A_idx = ep_idx\n",
    "        \n",
    "        if farthest_node_A_idx == -1:\n",
    "            raise ValueError(\"Could not find a reachable endpoint A.\")\n",
    "\n",
    "        # From endpoint A, find the farthest endpoint B and record the path\n",
    "        distances_from_A, predecessors_from_A = dijkstra(\n",
    "            csgraph=pixel_graph, directed=False, indices=farthest_node_A_idx, return_predecessors=True\n",
    "        )\n",
    "\n",
    "        farthest_node_B_idx = -1\n",
    "        max_dist_A_to_B = -1\n",
    "        for ep_idx in endpoint_nodes_indices:\n",
    "            if distances_from_A[ep_idx] > max_dist_A_to_B and np.isfinite(distances_from_A[ep_idx]):\n",
    "                max_dist_A_to_B = distances_from_A[ep_idx]\n",
    "                farthest_node_B_idx = ep_idx\n",
    "        \n",
    "        if farthest_node_B_idx == -1:\n",
    "            raise ValueError(\"Could not find a reachable endpoint B.\")\n",
    "            \n",
    "        # Reconstruct the path from A to B\n",
    "        path_indices = []\n",
    "        curr = farthest_node_B_idx\n",
    "        while curr != -9999:\n",
    "            path_indices.append(curr)\n",
    "            if curr == farthest_node_A_idx:\n",
    "                break\n",
    "            curr = predecessors_from_A[curr]\n",
    "\n",
    "        if not path_indices or path_indices[-1] != farthest_node_A_idx:\n",
    "            raise ValueError(\"Path reconstruction failed.\")\n",
    "\n",
    "        # Path is currently from B to A, so reverse it to be from A to B\n",
    "        path_indices.reverse()\n",
    "        \n",
    "        # --- Apply spatial preference to the two endpoints A and B ---\n",
    "\n",
    "        # Get the coordinates of endpoints A and B\n",
    "        endpoint_A_coord = coordinates_rc[farthest_node_A_idx]\n",
    "        endpoint_B_coord = coordinates_rc[farthest_node_B_idx]\n",
    "        \n",
    "        # Use the new function to decide which of A and B better fits the preference\n",
    "        two_endpoints_coords = np.array([endpoint_A_coord, endpoint_B_coord])\n",
    "        \n",
    "        preferred_start_index = select_skeleton_start_point(two_endpoints_coords, start_preference)\n",
    "\n",
    "        # --- Organize the path to ensure the start point is first ---\n",
    "        \n",
    "        # Based on the choice, set the final start point and reverse the path if needed\n",
    "        if preferred_start_index == 0:\n",
    "            # Endpoint A was chosen as the start. The path is already A -> B, so the order is correct.\n",
    "            start_coord_rc = endpoint_A_coord\n",
    "            longest_path_coords_rc = coordinates_rc[path_indices]\n",
    "        else:\n",
    "            # Endpoint B was chosen as the start. Reverse the A -> B path to B -> A.\n",
    "            start_coord_rc = endpoint_B_coord\n",
    "            path_indices.reverse() # Reverse the path\n",
    "            longest_path_coords_rc = coordinates_rc[path_indices]\n",
    "\n",
    "    if longest_path_coords_rc is None or len(longest_path_coords_rc) < 2:\n",
    "        raise ValueError(\"Skeleton path is invalid after final check.\")\n",
    "\n",
    "    return skeleton_display_img, longest_path_coords_rc, start_coord_rc\n",
    "\n",
    "\n",
    "print(\"Core processing functions defined successfully!\")\n",
    "print(\"Skeleton orientation control with START point on LEFT side\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Validation and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating target folder...\n",
      "Target folder validated: 1 image-JSON pairs found\n",
      "\n",
      "Validating mapping folders...\n",
      "Validating mapping folder 1: c2...\n",
      "Mapping folder 1 validated successfully\n",
      "\n",
      "Building file mappings for 1 valid mapping folders...\n",
      "File mapping complete: 1 file sets with 1 mapping(s) each.\n",
      "\n",
      "Validation successful! Ready to process 1 image sets.\n"
     ]
    }
   ],
   "source": [
    "def validate_and_load_files(target_dir, mapping_dirs):\n",
    "    \"\"\"Validate and load file mappings between target and mapping directories.\"\"\"\n",
    "    image_extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"}\n",
    "    \n",
    "    # 1. Validate Target Folder\n",
    "    print(\"Validating target folder...\")\n",
    "    try:\n",
    "        target_files = []\n",
    "        for filename in sorted(os.listdir(target_dir)):\n",
    "            name, ext = os.path.splitext(filename)\n",
    "            if ext.lower() in image_extensions:\n",
    "                img_path = os.path.join(target_dir, filename)\n",
    "                json_path = os.path.join(target_dir, name + \".json\")\n",
    "                if not os.path.exists(json_path):\n",
    "                    raise FileNotFoundError(f\"Target image '{filename}' is missing its corresponding JSON file.\")\n",
    "                target_files.append({'img': img_path, 'json': json_path, 'name': filename})\n",
    "        \n",
    "        if not target_files:\n",
    "            raise ValueError(\"No valid 'Image-JSON' pairs found in the target folder.\")\n",
    "        \n",
    "        print(f\"Target folder validated: {len(target_files)} image-JSON pairs found\")\n",
    "                \n",
    "    except (FileNotFoundError, ValueError) as e:\n",
    "        print(f\"Target Folder Error: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # 2. Validate each mapping folder\n",
    "    print(\"\\nValidating mapping folders...\")\n",
    "    valid_mapping_dirs = []\n",
    "    file_list_map = []\n",
    "    \n",
    "    for i, m_dir in enumerate(mapping_dirs):\n",
    "        print(f\"Validating mapping folder {i+1}: {os.path.basename(m_dir)}...\")\n",
    "        try:\n",
    "            map_files = [f for f in sorted(os.listdir(m_dir)) \n",
    "                        if os.path.splitext(f)[1].lower() in image_extensions]\n",
    "            \n",
    "            if len(map_files) != len(target_files):\n",
    "                raise ValueError(f\"File count mismatch! Target has {len(target_files)}, this folder has {len(map_files)}.\")\n",
    "            \n",
    "            # Check dimensions match\n",
    "            for j, target_file_info in enumerate(target_files):\n",
    "                target_img_path = target_file_info['img']\n",
    "                map_img_path = os.path.join(m_dir, map_files[j])\n",
    "                \n",
    "                # Check dimensions\n",
    "                target_img = cv2.imread(target_img_path)\n",
    "                if target_img is None:\n",
    "                    raise IOError(f\"Cannot read target image: {os.path.basename(target_img_path)}\")\n",
    "                h, w = target_img.shape[:2]\n",
    "                \n",
    "                map_img = cv2.imread(map_img_path)\n",
    "                if map_img is None:\n",
    "                    raise IOError(f\"Cannot read mapping image: {os.path.basename(map_img_path)}\")\n",
    "                mh, mw = map_img.shape[:2]\n",
    "                \n",
    "                if h != mh or w != mw:\n",
    "                    raise ValueError(f\"Size mismatch: '{target_file_info['name']}' ({w}x{h}) vs '{map_files[j]}' ({mw}x{mh})\")\n",
    "            \n",
    "            valid_mapping_dirs.append(m_dir)\n",
    "            print(f\"Mapping folder {i+1} validated successfully\")\n",
    "            \n",
    "        except (ValueError, IOError) as e:\n",
    "            print(f\"Mapping folder {i+1} validation failed: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not valid_mapping_dirs:\n",
    "        print(\"No valid mapping folders found!\")\n",
    "        return None\n",
    "    \n",
    "    # 3. Build the final file map list\n",
    "    print(f\"\\nBuilding file mappings for {len(valid_mapping_dirs)} valid mapping folders...\")\n",
    "    for i in range(len(target_files)):\n",
    "        map_entry = {\n",
    "            'target_img_path': target_files[i]['img'], \n",
    "            'target_json_path': target_files[i]['json'], \n",
    "            'mapping_img_paths': []\n",
    "        }\n",
    "        \n",
    "        for m_dir in valid_mapping_dirs:\n",
    "            map_files = [f for f in sorted(os.listdir(m_dir)) \n",
    "                        if os.path.splitext(f)[1].lower() in image_extensions]\n",
    "            map_entry['mapping_img_paths'].append(os.path.join(m_dir, map_files[i]))\n",
    "        \n",
    "        file_list_map.append(map_entry)\n",
    "    \n",
    "    print(f\"File mapping complete: {len(file_list_map)} file sets with {len(valid_mapping_dirs)} mapping(s) each.\")\n",
    "    return file_list_map, valid_mapping_dirs\n",
    "\n",
    "\n",
    "# Validate and load files\n",
    "validation_result = validate_and_load_files(TARGET_DIR, MAPPING_DIRS)\n",
    "\n",
    "if validation_result is None:\n",
    "    print(\"Validation failed! Please check your directory paths and file structure.\")\n",
    "else:\n",
    "    file_list_map, valid_mapping_dirs = validation_result\n",
    "    print(f\"\\nValidation successful! Ready to process {len(file_list_map)} image sets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing all images with controlled skeleton orientation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 1/1 [00:01<00:00,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully processed 1 image sets with top start preference!\n",
      "All skeleton START points are positioned at the top, and appear on the LEFT side of straightened outputs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def process_single_image_set(file_set, pad_to_canvas=False, output_width=200, output_height=200, start_preference='top'):\n",
    "    \"\"\"Process a single image set (target + mappings) with controlled skeleton orientation.\"\"\"\n",
    "    # Load target image and JSON annotation\n",
    "    target_img_cv = cv2.imread(file_set['target_img_path'])\n",
    "    img_height, img_width = target_img_cv.shape[:2]\n",
    "    \n",
    "    with open(file_set['target_json_path'], 'r', encoding='utf-8') as f:\n",
    "        labelme_data = json.load(f)\n",
    "    \n",
    "    # Extract polygon points (assuming first shape is the polygon)\n",
    "    polygon_points_xy = labelme_data['shapes'][0]['points']\n",
    "    poly_np = np.array(polygon_points_xy, dtype=np.int32)\n",
    "    \n",
    "    # Create mask from polygon\n",
    "    mask = np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "    cv2.fillPoly(mask, [poly_np], 255)\n",
    "    \n",
    "    # Extract skeleton and find longest path with controlled orientation\n",
    "    skeleton_img_raw, longest_path_coords_rc, start_coord_rc = extract_skeleton_and_longest_path(mask, start_preference)\n",
    "    \n",
    "    # Create enhanced visualization of skeleton with path and start point\n",
    "    skeleton_img_display = draw_skeleton_with_path_and_start(\n",
    "        skeleton_img_raw, longest_path_coords_rc, start_coord_rc,\n",
    "        upscale_factor=UPSCALE_FACTOR,\n",
    "        skeleton_thickness=SKELETON_THICKNESS,\n",
    "        path_thickness=PATH_THICKNESS\n",
    "    )\n",
    "    \n",
    "    # Straighten target image (START point will be on the left side of output)\n",
    "    straight_target_raw = straighten_polygon_region(target_img_cv, mask, longest_path_coords_rc)\n",
    "    \n",
    "    # Straighten mapping images\n",
    "    straight_mappings_raw = []\n",
    "    for map_img_path in file_set['mapping_img_paths']:\n",
    "        map_img_cv = cv2.imread(map_img_path)\n",
    "        straight_map = straighten_polygon_region(map_img_cv, mask, longest_path_coords_rc)\n",
    "        straight_mappings_raw.append(straight_map)\n",
    "    \n",
    "    # Apply padding/cropping if requested\n",
    "    if pad_to_canvas:\n",
    "        final_straight_target = pad_and_center_image(straight_target_raw, output_width, output_height)\n",
    "        final_straight_mappings = [pad_and_center_image(img, output_width, output_height) \n",
    "                                 for img in straight_mappings_raw]\n",
    "    else:\n",
    "        final_straight_target = straight_target_raw\n",
    "        final_straight_mappings = straight_mappings_raw\n",
    "    \n",
    "    return {\n",
    "        \"target_img_original\": target_img_cv,\n",
    "        \"polygon\": poly_np,\n",
    "        \"skeleton_img_display\": skeleton_img_display,\n",
    "        \"target_straight_img\": final_straight_target,\n",
    "        \"mapping_straight_imgs\": final_straight_mappings,\n",
    "        \"mapping_img_paths\": file_set['mapping_img_paths'],\n",
    "        \"start_coord_rc\": start_coord_rc\n",
    "    }\n",
    "\n",
    "\n",
    "# Process all images\n",
    "if 'file_list_map' in locals():\n",
    "    print(\"Processing all images with controlled skeleton orientation...\")\n",
    "    all_results = []\n",
    "    \n",
    "    for index in tqdm(range(len(file_list_map)), desc=\"Processing images\"):\n",
    "        file_set = file_list_map[index]\n",
    "        base_name = os.path.basename(file_set['target_img_path'])\n",
    "        \n",
    "        try:\n",
    "            results = process_single_image_set(file_set, PAD_TO_CANVAS, OUTPUT_WIDTH, OUTPUT_HEIGHT, SKELETON_START_PREFERENCE)\n",
    "            all_results.append(results)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing {base_name}: {e}\")\n",
    "            raise e\n",
    "    \n",
    "    print(f\"\\nSuccessfully processed {len(all_results)} image sets with {SKELETON_START_PREFERENCE} start preference!\")\n",
    "    print(f\"All skeleton START points are positioned at the {SKELETON_START_PREFERENCE}, and appear on the LEFT side of straightened outputs.\")\n",
    "else:\n",
    "    print(\"No valid files to process. Please run the validation cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigation Controls\n",
    "\n",
    "Navigate through results with previous/next buttons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9163b13b4ad94e73b3b6d6ea66c08514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Quick Navigation</h3>'), HTML(value='<p>Use the buttons to navigate through ima…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_navigation_controls():\n",
    "    \"\"\"Create navigation controls with previous/next buttons.\"\"\"\n",
    "    if not ('all_results' in locals() or 'all_results' in globals()) or not all_results:\n",
    "        print(\"No results to display. Please run the processing cell first.\")\n",
    "        return\n",
    "    \n",
    "    # Current index tracker\n",
    "    current_index = {'value': 0}\n",
    "    \n",
    "    # Create buttons\n",
    "    prev_button = widgets.Button(\n",
    "        description='Previous',\n",
    "        disabled=False,\n",
    "        button_style='info',\n",
    "        tooltip='Go to previous image'\n",
    "    )\n",
    "    \n",
    "    next_button = widgets.Button(\n",
    "        description='Next',\n",
    "        disabled=False,\n",
    "        button_style='info',\n",
    "        tooltip='Go to next image'\n",
    "    )\n",
    "    \n",
    "    info_label = widgets.HTML(value=f\"<b>Image 1 of {len(all_results)}</b>\")\n",
    "    \n",
    "    # Create output for images\n",
    "    nav_output = widgets.Output()\n",
    "    \n",
    "    def show_current_image():\n",
    "        \"\"\"Display current image and update controls.\"\"\"\n",
    "        idx = current_index['value']\n",
    "        \n",
    "        # Update info label\n",
    "        info_label.value = f\"<b>Image {idx + 1} of {len(all_results)}</b>\"\n",
    "        \n",
    "        # Update button states\n",
    "        prev_button.disabled = (idx == 0)\n",
    "        next_button.disabled = (idx == len(all_results) - 1)\n",
    "        \n",
    "        # Display image\n",
    "        with nav_output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            result = all_results[idx]\n",
    "            file_info = file_list_map[idx]\n",
    "            base_name = os.path.basename(file_info['target_img_path'])\n",
    "            \n",
    "            print(f\"Displaying results for: {base_name} (Image {idx + 1}/{len(all_results)})\")\n",
    "            print(f\"Skeleton start preference: {SKELETON_START_PREFERENCE} -> START on LEFT side of straightened output\")\n",
    "            \n",
    "            # Calculate the number of rows needed\n",
    "            num_mappings = len(result['mapping_straight_imgs'])\n",
    "            num_rows = 1 + num_mappings  # 1 for target + N for mappings\n",
    "            \n",
    "            fig, axes = plt.subplots(num_rows, 3, figsize=(18, 6 * num_rows))\n",
    "            if num_rows == 1:\n",
    "                axes = axes.reshape(1, -1)\n",
    "            \n",
    "            # Display target row\n",
    "            row = 0\n",
    "            \n",
    "            # Original target with enhanced annotation\n",
    "            target_with_poly = draw_polygon_with_fine_lines(\n",
    "                result['target_img_original'], \n",
    "                result['polygon'], \n",
    "                color=(0, 255, 0), \n",
    "                thickness=CONTOUR_THICKNESS,\n",
    "                upscale_factor=UPSCALE_FACTOR\n",
    "            )\n",
    "            axes[row, 0].imshow(cv2.cvtColor(target_with_poly, cv2.COLOR_BGR2RGB))\n",
    "            axes[row, 0].set_title(f\"Target: {os.path.basename(TARGET_DIR)}\\nOriginal + Annotation\", fontsize=12, pad=10)\n",
    "            axes[row, 0].axis('off')\n",
    "            \n",
    "            # Enhanced skeleton display with START marker\n",
    "            axes[row, 1].imshow(cv2.cvtColor(result['skeleton_img_display'], cv2.COLOR_BGR2RGB))\n",
    "            axes[row, 1].set_title(f\"Skeleton + Longest Path\\nSTART ({SKELETON_START_PREFERENCE}) marked in green\", fontsize=12, pad=10)\n",
    "            axes[row, 1].axis('off')\n",
    "            \n",
    "            # Straightened target\n",
    "            axes[row, 2].imshow(cv2.cvtColor(result['target_straight_img'], cv2.COLOR_BGR2RGB))\n",
    "            axes[row, 2].set_title(f\"Straightened Target\\nSTART -> LEFT side\", fontsize=12, pad=10)\n",
    "            axes[row, 2].axis('off')\n",
    "            \n",
    "            # Display mapping rows\n",
    "            for i, map_img_path in enumerate(result['mapping_img_paths']):\n",
    "                row = i + 1\n",
    "                map_dir_name = os.path.basename(valid_mapping_dirs[i])\n",
    "                \n",
    "                # Original mapping with enhanced annotation\n",
    "                map_img = cv2.imread(map_img_path)\n",
    "                map_with_poly = draw_polygon_with_fine_lines(\n",
    "                    map_img, \n",
    "                    result['polygon'], \n",
    "                    color=(0, 255, 0), \n",
    "                    thickness=CONTOUR_THICKNESS,\n",
    "                    upscale_factor=UPSCALE_FACTOR\n",
    "                )\n",
    "                axes[row, 0].imshow(cv2.cvtColor(map_with_poly, cv2.COLOR_BGR2RGB))\n",
    "                axes[row, 0].set_title(f\"Map {i+1}: {map_dir_name}\\nOriginal + Annotation\", fontsize=12, pad=10)\n",
    "                axes[row, 0].axis('off')\n",
    "                \n",
    "                # Same enhanced skeleton for all images\n",
    "                axes[row, 1].imshow(cv2.cvtColor(result['skeleton_img_display'], cv2.COLOR_BGR2RGB))\n",
    "                axes[row, 1].set_title(f\"Skeleton + Longest Path\\nSame START point for all\", fontsize=12, pad=10)\n",
    "                axes[row, 1].axis('off')\n",
    "                \n",
    "                # Straightened mapping\n",
    "                axes[row, 2].imshow(cv2.cvtColor(result['mapping_straight_imgs'][i], cv2.COLOR_BGR2RGB))\n",
    "                axes[row, 2].set_title(f\"Straightened Map {i+1}\\nSTART -> LEFT side\", fontsize=12, pad=10)\n",
    "                axes[row, 2].axis('off')\n",
    "            \n",
    "            plt.tight_layout(pad=2.0)\n",
    "            plt.show()\n",
    "    \n",
    "    def on_prev_clicked(b):\n",
    "        if current_index['value'] > 0:\n",
    "            current_index['value'] -= 1\n",
    "            show_current_image()\n",
    "    \n",
    "    def on_next_clicked(b):\n",
    "        if current_index['value'] < len(all_results) - 1:\n",
    "            current_index['value'] += 1\n",
    "            show_current_image()\n",
    "    \n",
    "    # Connect button events\n",
    "    prev_button.on_click(on_prev_clicked)\n",
    "    next_button.on_click(on_next_clicked)\n",
    "    \n",
    "    # Layout\n",
    "    controls = widgets.HBox([prev_button, info_label, next_button], \n",
    "                           layout=widgets.Layout(justify_content='center'))\n",
    "    \n",
    "    display(widgets.VBox([\n",
    "        widgets.HTML(\"<h3>Quick Navigation</h3>\"),\n",
    "        widgets.HTML(\"<p>Use the buttons to navigate through images:</p>\"),\n",
    "        controls,\n",
    "        nav_output\n",
    "    ]))\n",
    "    \n",
    "    # Show first image\n",
    "    show_current_image()\n",
    "\n",
    "\n",
    "# Create navigation controls\n",
    "if 'all_results' in locals() and all_results:\n",
    "    create_navigation_controls()\n",
    "else:\n",
    "    print(\"No results available for navigation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "\n",
    "Save the processed images to files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8137c04059fe43bb95e95a139ffccb9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Save Results</h3>'), HTML(value='<p><b>Output Directory:</b> /Users/jyzerresico…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save_as_individual_files(all_results, file_list_map, valid_mapping_dirs, output_dir):\n",
    "    \"\"\"Save each straightened image as an individual TIFF file.\"\"\"\n",
    "    print(\"Saving individual TIFF files...\")\n",
    "    \n",
    "    num_maps = len(valid_mapping_dirs)\n",
    "    total_files_to_save = len(all_results) * (1 + num_maps)\n",
    "    saved_count = 0\n",
    "    \n",
    "    try:\n",
    "        for index, result_set in enumerate(tqdm(all_results, desc=\"Saving files\")):\n",
    "            # Get source filename\n",
    "            source_path = file_list_map[index]['target_img_path']\n",
    "            base_name = os.path.basename(source_path)\n",
    "            name_only, _ = os.path.splitext(base_name)\n",
    "            \n",
    "            # Save straightened target image\n",
    "            target_img_np = result_set['target_straight_img']\n",
    "            target_pil = Image.fromarray(cv2.cvtColor(target_img_np, cv2.COLOR_BGR2RGB))\n",
    "            target_out_path = os.path.join(output_dir, f\"{name_only}_target_straight.tif\")\n",
    "            target_pil.save(target_out_path, compression='tiff_lzw')\n",
    "            saved_count += 1\n",
    "            \n",
    "            # Save all straightened mapping images\n",
    "            for i, map_img_np in enumerate(result_set['mapping_straight_imgs']):\n",
    "                map_pil = Image.fromarray(cv2.cvtColor(map_img_np, cv2.COLOR_BGR2RGB))\n",
    "                map_dir_name = os.path.basename(valid_mapping_dirs[i])\n",
    "                map_out_path = os.path.join(output_dir, f\"{name_only}_map_{map_dir_name}_straight.tif\")\n",
    "                map_pil.save(map_out_path, compression='tiff_lzw')\n",
    "                saved_count += 1\n",
    "        \n",
    "        print(f\"Successfully saved {saved_count} individual TIFF files to {output_dir}\")\n",
    "        print(f\"Check your output directory: {output_dir}\")\n",
    "        print(f\"All straightened images have START point ({SKELETON_START_PREFERENCE}) on the LEFT side\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during saving: {e}\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "def save_as_stacks(all_results, valid_mapping_dirs, output_dir):\n",
    "    \"\"\"Save results as multi-frame TIFF stacks.\"\"\"\n",
    "    print(\"Saving multi-frame TIFF stacks...\")\n",
    "    \n",
    "    num_mapping_channels = len(valid_mapping_dirs)\n",
    "    \n",
    "    # Collect target images\n",
    "    target_images_pil = []\n",
    "    mapping_images_pil = [[] for _ in range(num_mapping_channels)]\n",
    "    \n",
    "    print(\"Collecting images for stacks...\")\n",
    "    for result_set in tqdm(all_results, desc=\"Collecting images\"):\n",
    "        # Add target image\n",
    "        target_img_np = result_set['target_straight_img']\n",
    "        target_images_pil.append(Image.fromarray(cv2.cvtColor(target_img_np, cv2.COLOR_BGR2RGB)))\n",
    "        \n",
    "        # Add mapping images\n",
    "        for i, map_img_np in enumerate(result_set['mapping_straight_imgs']):\n",
    "            mapping_images_pil[i].append(Image.fromarray(cv2.cvtColor(map_img_np, cv2.COLOR_BGR2RGB)))\n",
    "    \n",
    "    try:\n",
    "        stacks_saved = 0\n",
    "        \n",
    "        # Save target stack\n",
    "        if target_images_pil:\n",
    "            out_path_target = os.path.join(output_dir, \"Target_Stack.tif\")\n",
    "            target_images_pil[0].save(out_path_target, save_all=True, append_images=target_images_pil[1:], \n",
    "                                    format='TIFF', compression='tiff_lzw')\n",
    "            print(f\"Saved target stack: Target_Stack.tif ({len(target_images_pil)} frames)\")\n",
    "            stacks_saved += 1\n",
    "        \n",
    "        # Save mapping stacks\n",
    "        for i, map_image_list in enumerate(mapping_images_pil):\n",
    "            if map_image_list:\n",
    "                map_dir_name = os.path.basename(valid_mapping_dirs[i])\n",
    "                out_path_map = os.path.join(output_dir, f\"{map_dir_name}_Stack.tif\")\n",
    "                map_image_list[0].save(out_path_map, save_all=True, append_images=map_image_list[1:], \n",
    "                                     format='TIFF', compression='tiff_lzw')\n",
    "                print(f\"Saved mapping stack {i+1}: {map_dir_name}_Stack.tif ({len(map_image_list)} frames)\")\n",
    "                stacks_saved += 1\n",
    "        \n",
    "        print(f\"\\nSuccessfully saved {stacks_saved} multi-frame TIFF stacks!\")\n",
    "        print(f\"Check your output directory: {output_dir}\")\n",
    "        print(f\"All straightened images have START point ({SKELETON_START_PREFERENCE}) on the LEFT side\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during saving stacks: {e}\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "# Create interactive save controls\n",
    "def create_save_controls():\n",
    "    \"\"\"Create interactive save controls.\"\"\"\n",
    "    if not ('all_results' in locals() or 'all_results' in globals()) or not all_results:\n",
    "        print(\"No results to save. Please run the processing cell first.\")\n",
    "        return\n",
    "    \n",
    "    # Create buttons\n",
    "    save_individual_btn = widgets.Button(\n",
    "        description='Save Individual Files',\n",
    "        button_style='success',\n",
    "        tooltip='Save each image as a separate TIFF file'\n",
    "    )\n",
    "    \n",
    "    save_stacks_btn = widgets.Button(\n",
    "        description='Save as Stacks',\n",
    "        button_style='warning',\n",
    "        tooltip='Save as multi-frame TIFF stacks'\n",
    "    )\n",
    "    \n",
    "    # Output for save status\n",
    "    save_output = widgets.Output()\n",
    "    \n",
    "    def on_save_individual(b):\n",
    "        with save_output:\n",
    "            clear_output(wait=True)\n",
    "            save_as_individual_files(all_results, file_list_map, valid_mapping_dirs, OUTPUT_DIR)\n",
    "    \n",
    "    def on_save_stacks(b):\n",
    "        with save_output:\n",
    "            clear_output(wait=True)\n",
    "            save_as_stacks(all_results, valid_mapping_dirs, OUTPUT_DIR)\n",
    "    \n",
    "    # Connect events\n",
    "    save_individual_btn.on_click(on_save_individual)\n",
    "    save_stacks_btn.on_click(on_save_stacks)\n",
    "    \n",
    "    # Layout\n",
    "    save_controls = widgets.HBox([save_individual_btn, save_stacks_btn], \n",
    "                                layout=widgets.Layout(justify_content='center'))\n",
    "    \n",
    "    display(widgets.VBox([\n",
    "        widgets.HTML(\"<h3>Save Results</h3>\"),\n",
    "        widgets.HTML(f\"<p><b>Output Directory:</b> {OUTPUT_DIR}</p>\"),\n",
    "        widgets.HTML(f\"<p><b>Ready to save:</b> {len(all_results)} processed image sets</p>\"),\n",
    "        widgets.HTML(f\"<p><b>Skeleton orientation:</b> START point ({SKELETON_START_PREFERENCE}) -> LEFT side of outputs</p>\"),\n",
    "        save_controls,\n",
    "        save_output\n",
    "    ]))\n",
    "\n",
    "\n",
    "# Create save controls\n",
    "if 'all_results' in locals() and all_results:\n",
    "    create_save_controls()\n",
    "else:\n",
    "    print(\"No results available for saving.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
